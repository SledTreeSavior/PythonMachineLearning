# -*- coding: utf-8 -*-
"""KAS_EEDS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uKYESD9sfTzXYc4O5o9N2fYtlk7SuOd5
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import os
import requests
import pandas as pd 
import matplotlib.pyplot as plt
import sklearn

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error as mse

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import plot_confusion_matrix
from sklearn.ensemble import BaggingClassifier
import seaborn as sns
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_val_score
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import plot_precision_recall_curve
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.tree import DecisionTreeClassifier
import tensorflow as tf
from sklearn.compose import ColumnTransformer
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.metrics import classification_report
from matplotlib.pyplot import figure
from sklearn import metrics

"""> For example, for solving a regression problem, you may use linear regression, polynomial regression, regularized regression (either linear or polynomial)"""

# import the dataset
from google.colab import drive
drive.mount('/content/drive')
data = pd.read_excel("/content/drive/My Drive/School/Machine Learning/Final/ENB2012_data.xlsx")
print(data)

data.isnull().sum()

data.dropna()

data.columns = ['compactness','surface_area','wall_area','roof_area','height',\
                  'orientation','glazing_area','distribution','heating_load','cooling_load']

data.describe()

X = data.drop(['heating_load','cooling_load'], axis=1)

y = data[['heating_load','cooling_load']]
y_heat = data[['heating_load']]
y_cool = data[['cooling_load']]

plt.plot(X, y, "b.")
plt.xlabel("$x_1$", fontsize=18)
plt.ylabel("$y$", rotation=0, fontsize=18)
plt.show()

import matplotlib.pyplot as plt
X1 = np.arange(0,len(X),1)
plt.scatter(X1, y_heat)
plt.xlabel("Building Features")
plt.ylabel("Heating Features")
plt.title("Heating Data")

import matplotlib.pyplot as plt
X1 = np.arange(0,len(X),1)
plt.scatter(X1, y_cool)
plt.xlabel("Building Features")
plt.ylabel("Cooling Efficiency")
plt.title("Cooling Data")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

model = LinearRegression()
model.fit(X_train, y_train)

expected = y_test
predicted = model.predict(X_test)

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
R2 = lin_reg.score(X_train, y_train)
print('R2:', R2)
print('intercept:', lin_reg.intercept_)
print('slope:', lin_reg.coef_)

y_pred = lin_reg.predict(X_test)
print(y_pred)

from sklearn.metrics import r2_score
lin_reg_y_pred = lin_reg.predict(X_test)
print('r2_score', r2_score(y_test, lin_reg_y_pred))

from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_val_score
y_train_pred = cross_val_predict(lin_reg, X_train, y_train, cv = 3)
y_scores = cross_val_score(lin_reg, X_train, y_train, cv = 3)
print(y_scores)

from sklearn.metrics import mean_squared_error
mean_squared_error(y_test, y_pred)

"""> Polynomial Regression"""

from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=8)

X_poly_train = poly.fit_transform(X_train)
X_poly_test = poly.fit_transform(X_test)

poly_reg = LinearRegression()
poly_reg.fit(X_poly_train, y_train)

poly_reg_y_pred = poly_reg.predict(X_poly_test)
print('r2_score', r2_score(y_test, poly_reg_y_pred))

mean_squared_error(y_test, poly_reg_y_pred)

from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_val_score
y_train_pred3 = cross_val_predict(poly_reg, X_train, y_train, cv = 3)
y_scores = cross_val_score(poly_reg, X_train, y_train, cv = 3)
print(y_scores)

"""> NN"""

from keras.layers import Dense, Activation, Dropout
from keras.models import Sequential
model = Sequential()
model.add(Dense(200, input_dim=8))
model.add(Dense(2, activation = 'linear'))
model.compile(loss = "mse", optimizer = 'adam', metrics = ['mse'])

history = model.fit(X_train, y_train, validation_split = 0.2, epochs = 300, batch_size = 10, verbose = 1)

plt.plot(history.history['mse'])
plt.plot(history.history['loss'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model.summary()

model_y_pred = model.predict(X_test)

model_y_pred = model.predict(X_test)
print('r2_score', r2_score(y_test, model_y_pred))