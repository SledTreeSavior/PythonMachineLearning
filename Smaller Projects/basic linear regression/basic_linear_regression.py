# -*- coding: utf-8 -*-
"""HW2_posted.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13TpkJ3hRitNx3jIdtWn4zw25ci6s78vw
"""

import matplotlib.pyplot as plt
import numpy as np

# Linear Algebra
# Make an array A of size (2x3) with values 1 through 6 (the first row contains 1,2,3)
A = np.array([[1, 2, 3], [4, 5, 6]])
# Make an array B of size (3x5) with values 1 through 15 (the first row contains 1,2,3,4,5)
B = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15]])
# print the result of A x B
np.matmul(A, B)

# Can we compute B x A?
#np.matmul(B, A)
# No, AxB is (2x3)x(3x5)
# BxA is (3x5)x(2x3) and the inside dimensions are not the same

# Pandas 
# make a numpy array with values 1 to 5.
import pandas as pd

C = np.array([1, 2, 3, 4, 5])

# convert it into a series
S = pd.Series(C)

# Duplicate the series
S2 = S

# Now combine the original series and the copy of the series into a dataframe
D = pd.DataFrame(S.append(S2, ignore_index = True))

# Convert all the ints in the dataframe to floats and print it
D = D.astype(float)
print (D.dtypes)

# import real_estate.csv (make sure that the index column is the same as No in the data set)
from google.colab import files
data_to_load = files.upload()

D = pd.read_csv('real_estate.csv', index_col=['No'])
D

# Are there any null values in the dataset? Drop any missing data if exist. 
D.dropna()

# Create X as a 1-D array of the distance to the nearest MRT station, and y as the housing price
X = D['X3 distance to the nearest MRT station'].to_numpy()
y = D['Y house price of unit area'].to_numpy()

# What is the number of samples in the data set? To do this, you can look at the "shape" of X and y
print('X:', X.shape)
print('y:', y.shape)

# Print the first 5 elements of X and y 
print('X:', X[:5])
print('y:', y[:5])

# split the data into train and test sets using sklearn's train_test_split, with test_size = 1/3
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

# Print the number of train and test samples
print(X_train.shape)
print(X_test.shape)

X_train = X_train.reshape(-1, 1)
X_test = X_test.reshape(-1, 1)

"""## Find the line of best fit using a Linear Regression and show the result of coefficients and intercept"""

print('X_train:', X_train.shape)
print('X_test:', X_test.shape)

# using your LinearRegression's predict method, make a y predictions for test set and print them
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)
y_pred = reg.predict(X_test)
print(y_pred[:10])

from sklearn.metrics import explained_variance_score

explained_variance_score(y_test, LinearRegression().fit(X_train, y_train).predict(X_test))

"""Use subplot to plot 2 figures side by side: one for using predict method and the other for using coef and intercept method. In each figure, use scatter plot for the test data and draw the regression line

Make sure that you label both axes with appropriate names. 
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

plt.subplot(1, 2, 1)
plt.plot(X_test, y_pred, "r-")
plt.plot(X, y, "b.")
plt.title('predict method')
plt.xlabel('X3 distance to the nearest MRT station')
plt.ylabel('Y house price of unit area')

plt.subplot(1, 2, 2)
#plt.plot(X_test, y_pred, "r-")
plt.plot(X, y, "b.")
plt.title('coef and intercept method')
plt.xlabel('X3 distance to the nearest MRT station')
plt.ylabel('Y house price of unit area')

plt.subplots_adjust(left=0.1,
                    bottom=0.1, 
                    right=0.9, 
                    top=0.9, 
                    wspace=0.4, 
                    hspace=0.4)

"""Predict the price of houses with a distance of 1000, 2000, 3000 from the nearest MRT. """



"""# Polynomial Regression
Train the Polynomial Regression model on the *whole* dataset  (degree=2, include_bias = False)

Graph the polynomial regression result against the scatterplot


"""



# Polynomial Regression
#Training the Polynomial Regression model on the whole dataset (degree=3) and graph the polynomial against the scatterplot

# Which model is more sensible? Degree 2 or 3?