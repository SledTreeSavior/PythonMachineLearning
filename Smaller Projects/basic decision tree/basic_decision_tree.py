# -*- coding: utf-8 -*-
"""HW4Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UZf29G04W7vRhia66txgYQh_0_FOH2Gx

# COMP4220: Machine Learning, Fall 2021, Assignment 4


> ## **Please submit one pdf file for all questions.**

# 1. What is the fundamental idea behind Support Vector Machines?

> ## **Your answer here**

> A support vector machine creates a street with two dotted lines separating data points into two classes. Ideally, these two dotted lines are as far apart as possible. The line directly in the middle of the street is the decision boundary which is a stright line in the case of LinearSVM. In a polynomial case there is one line which acts as the decision boundary. The value "kernel" can be set to change the type of training.

# 2. If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?

> ## **Your answer here**

> No, it is not a good idea to try to scaling the input features. This is because decision trees do not require feature scaling, so doing so would not help the case of underfitting. It is a nonparametric model.

# 3.If you have trained five different models on the exact same training data, and they all achieve 95% precision, is there any chance that you can combine these models to get better results? If so, how? If not, why?

> ## **Your answer here**

> Yes, there is. If the models are trained on the same data, it is best if they make predicitions using very different models/methods. Using hard-voting, you may aggregate the predictions of each model and predict the class that gets the most votes. The result of hard-voting is the entire ensemble's best prediction. This can be better than the average 95% precision because of the wisdom of the crowd, the idea that the aggregate answer of many predictors is often more accurate than the best single predictor.

# Programming assignments (SVM, Decision Tree, Random Forest)
"""

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## P0. Import the dataset (breast_cancer_wisconsin). 
### 1. Use ".info()"to get more information about the dataset.
"""

from google.colab import drive
drive.mount('/content/drive')
BCW = pd.read_csv("/content/drive/My Drive/School/Machine Learning/Homework/HW4/HW4Data.csv")
BCW

"""# P1. Programming assignment(SVM)

## P1.1 From the dataset we can see that the ID and Unnamed are irrelevant to our model development. 
<h3>
    <ol>
        <li>Remove the the ID and Unnamed features from the dataset.</li>
        <li>Make X all the features in the dataset excluding the diagnosis. 
            Hint: your final X should only have features that end in "mean", "se", and "worst".</li>
        <li>Make y the diagnosis feature and replace each "M" with 1, and each "B" with 0 using ".replace()"  </li>
    </ol>
</h3>
"""

BCW.drop('id', inplace=True, axis=1)
BCW.drop('Unnamed: 32', inplace=True, axis=1)
print(BCW)

y = BCW['diagnosis']
y = y.replace("M", 1)
y = y.replace("B", 0)
print(y)

X = BCW.loc[:, BCW.columns.str.endswith('mean' or 'se' or 'worst')]
print(X)

"""## P1.2 Split the dataset into the Training set(%75) and Test set(%25). 
> ### Use "train_test_split" from sklearn.model_selection to get X_train, X_test, y_train, y_test.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

"""## P1.3 Apply the Feature Scaling method for X_train and X_test.
> ### __Hint__: use StandardScaler.fit_transform(X_train) for "X_train" and use StandardScaler.transform(X_test) for "X_test".



"""

from sklearn.preprocessing import StandardScaler

StandardScaler = StandardScaler()
StandardScaler.fit_transform(X_train)
StandardScaler.transform(X_test)

"""## P1.4 Train the linear SVM model on the Training set with (random_state = 42 and probability =True)."""

from sklearn.svm import SVC

svm_clf = SVC(kernel = 'linear', probability = True, random_state = 42)
svm_clf.fit(X_train, y_train)

"""## P1.5 Predict the Test set results and print the result.

"""

y_pred_svm = svm_clf.predict(X_test)
print(y_pred_svm)

"""## P1.6 Show the performance of the model.
<h2>
    <ol>
        <li>Accuracy score.</li>
        <li>Precision.</li>
        <li>Recall.</li>
        <li>F1 score.</li>
    </ol>
</h2>
"""

print('Accuracy: {}'.format(accuracy_score(y_test, y_pred_svm)))

from sklearn.metrics import precision_score
print(precision_score(y_test, y_pred_svm, average=None))

from sklearn.metrics import recall_score
print(recall_score(y_test, y_pred_svm, average=None))

from sklearn.metrics import f1_score
print(f1_score(y_test, y_pred_svm, average=None))

"""## P1.7 Make the Confusion Matrix and show the result."""

from sklearn.metrics import confusion_matrix
cnf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
cnf_matrix_svm

"""# P2. Programming assignment(Decision Tree)

## P2.1 Train the Decision Tree Classification on the Training set, (criterion = 'entropy', random_state = 42).
"""

from sklearn.tree import DecisionTreeClassifier
tree_clf = DecisionTreeClassifier(criterion='entropy', random_state=42)
tree_clf.fit(X_train, y_train)

"""##  P2.2 Predict the Test set results and print them."""

y_pred_tree = tree_clf.predict(X_test)
print(y_pred_tree)

"""## P2.3 Show the performance of the model.
<h2>
    <ol>
        <li>Accuracy score.</li>
        <li>Precision.</li>
        <li>Recall.</li>
        <li>F1 score.</li>
    </ol>
</h2>
"""

print('Accuracy: {}'.format(accuracy_score(y_test, y_pred_tree)))
print('Precision: {}'.format(precision_score(y_test, y_pred_tree, average=None)))
print('Recall: {}'.format(recall_score(y_test, y_pred_tree, average=None)))
print('F1 Score: {}'.format(f1_score(y_test, y_pred_tree, average=None)))

"""## P2.4 Make the Confusion Matrix and show the result."""

cnf_matrix_tree = confusion_matrix(y_test, y_pred_tree)
cnf_matrix_tree

"""# P3. Programming assignment(Random Forest)

## P3.1 Train the Random Forest Classification on the Training set (criterion = 'entropy', random_state = 42).
"""

from sklearn.ensemble import RandomForestClassifier
rnd_clf = RandomForestClassifier(criterion='entropy', random_state=42)
rnd_clf.fit(X_train, y_train)

"""##  P3.2 Predict the Test set results."""

y_pred_rnd = rnd_clf.predict(X_test)
print(y_pred_rnd)

"""## P3.3 Make the Confusion Matrix and show the result."""

cnf_matrix_rnd = confusion_matrix(y_test, y_pred_rnd)
cnf_matrix_rnd

"""## P3.3 Compare the SVM, Decision Tree, and Random Forest
### P3.1 Plot the ROC curves for SVM, Decision Tree, and Random Forest on the same figure (use legend to show AUC values too)
"""

from sklearn.metrics import roc_curve, auc, precision_recall_curve

fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_pred_svm)
plt.plot(fpr_svm, tpr_svm, "r", linewidth=2, label=" AUC SVM ="+str(auc(fpr_svm, tpr_svm)))

fpr_tree, tpr_tree, thresholds_tree = roc_curve(y_test, y_pred_tree)
plt.plot(fpr_tree, tpr_tree, "g", linewidth=2, label=" AUC TREE ="+str(auc(fpr_tree, tpr_tree)))

fpr_rnd, tpr_rnd, thresholds_rnd = roc_curve(y_test, y_pred_rnd)
plt.plot(fpr_rnd, tpr_rnd, "b", linewidth=2, label=" AUC RND="+str(auc(fpr_rnd, tpr_rnd)))

plt.plot([0,1], [0,1], 'k--')

plt.legend(loc='lower right')
plt.grid()

"""## P3.4 Based on the ROC curve, which classifier is the best?"""

#Random Forest has the ROC curve with the highest AUC, meaning that it is the best classifier.

"""# P4. Train and fine-tune a Decision Tree for the make_moons dataset 
## Note: Make_moons is a 2d binary classification dataset in the sklearn library. When plotted, it forms a pattern that looks like two moon crescents.
"""

from sklearn.datasets import make_moons

"""## P4.1.  Use X, y = make_moons(n_samples=10000, noise=0.4) to generate a moons dataset."""

X_mm, y_mm = make_moons(n_samples=10000, noise=0.4)

"""## P4.2. Use train_test_split() to split the dataset into 75:25 ratio."""

X_mm_train, X_mm_test, y_mm_train, y_mm_test = train_test_split(X_mm, y_mm, test_size=0.25)

tree_mm_clf = DecisionTreeClassifier(criterion='entropy', random_state=42)
tree_mm_clf.fit(X_mm_train, y_mm_train)
y_mm_pred = tree_mm_clf.predict(X_mm_test)
print(y_mm_pred)

"""## P4.3. Use grid search with cross-validation (with the help of the GridSearchCV class) to find good hyperparameter values for a DecisionTreeClassifier.

### Train it on the full training set using these hyperparameters, and measure your modelâ€™s performance on the test set. 

### By default, GridSearchCV trains the best model found on the whole training set (you can change this by setting refit=False), so you don't need to do it again.

> ### __Hint__: try various values for max_leaf_nodes.



"""

from sklearn.model_selection import GridSearchCV

MLN = np.arange(2, 100, 1)
print(MLN)

param_grid = [
  {'criterion':['gini','entropy'], 'max_leaf_nodes':MLN}
]
clf_GSCV = GridSearchCV(tree_mm_clf, param_grid, cv=5)
clf_GSCV.fit(X_mm_train, y_mm_train)
y_mm_pred = clf_GSCV.predict(X_mm_test)
print(y_mm_pred)

"""## P4.4. Evaluate the model's accuracy and show the result."""

print('Accuracy: {}'.format(accuracy_score(y_mm_test, y_mm_pred)))